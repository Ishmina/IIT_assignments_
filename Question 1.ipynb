{
 "cells": [
  {
   "cell_type": "raw",
   "id": "8c79c3be-10e2-4a43-bba1-c51387d197a7",
   "metadata": {},
   "source": [
    "The MNIST dataset consists of 70,000 images of handwritten digits, where \r\n",
    "each image is 28x28 pixels. Classify each image into one of the 10 classes \r\n",
    "(digits 0-9  \r\n",
    "A. Using a Multi-Layer Perceptron (MLP) classifier \r\n",
    "B. Using a Convolutional Neural Network (CNN) classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74de50c2-b173-453a-95ca-299d2d46a873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize the pixel values (0–255 to 0–1)\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bae3da-ff47-48f5-b8d5-0580fe181f96",
   "metadata": {},
   "source": [
    "# A. Using a Multi-Layer Perceptron (MLP) classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f73e74-8b8d-4190-9b5c-c7f4a2870fc3",
   "metadata": {},
   "source": [
    "## Step A1: Preprocess Data for MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f871a5d0-2e73-4474-b2dd-792ee4e858f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten images from 28x28 to 784\n",
    "x_train_flat = x_train.reshape((60000, 28*28))\n",
    "x_test_flat = x_test.reshape((10000, 28*28))\n",
    "\n",
    "# One-hot encode labels (e.g., 5 → [0 0 0 0 0 1 0 0 0 0])\n",
    "y_train_cat = to_categorical(y_train)\n",
    "y_test_cat = to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a354d03b-8761-4823-82ff-49fc9ec8157c",
   "metadata": {},
   "source": [
    "## Step A2: Build the MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "197e91d0-fd6a-4a51-a7f8-f2c9bf9992ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "mlp_model = Sequential([\n",
    "    Input(shape=(784,)),               # Input layer\n",
    "    Dense(128, activation='relu'),     # Hidden layer\n",
    "    Dense(64, activation='relu'),      # Hidden layer\n",
    "    Dense(10, activation='softmax')    # Output layer\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4d0232-7ed2-407a-b811-3cf0339b9711",
   "metadata": {},
   "source": [
    "## Step A3: Compile and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13fe57f1-377f-426b-8633-ec46b67ce087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8024 - loss: 0.6951 - val_accuracy: 0.9451 - val_loss: 0.1933\n",
      "Epoch 2/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9512 - loss: 0.1698 - val_accuracy: 0.9588 - val_loss: 0.1423\n",
      "Epoch 3/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9662 - loss: 0.1141 - val_accuracy: 0.9645 - val_loss: 0.1206\n",
      "Epoch 4/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9751 - loss: 0.0859 - val_accuracy: 0.9637 - val_loss: 0.1153\n",
      "Epoch 5/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9809 - loss: 0.0651 - val_accuracy: 0.9685 - val_loss: 0.1042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2a2e27c9290>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "mlp_model.fit(x_train_flat, y_train_cat, epochs=5, batch_size=128, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25d2b45-5438-4ce5-9fde-9f849ea50d75",
   "metadata": {},
   "source": [
    "## Step A4: Evaluate MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "843d33cd-b1eb-4bd8-b217-a66ed161a50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.9660 - loss: 0.1062\n",
      "MLP Test Accuracy: 97.03 %\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = mlp_model.evaluate(x_test_flat, y_test_cat)\n",
    "print(f\"MLP Test Accuracy: {test_acc * 100:.2f} %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f472769-1a5e-45bf-9d22-88de42f0e253",
   "metadata": {},
   "source": [
    "# B. Using a Convolutional Neural Network (CNN) classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9610fa90-af30-46df-9cfc-775421bfcc14",
   "metadata": {},
   "source": [
    "## Step B1: Preprocess Data for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b0f193b-6788-471e-b582-621387b903b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape images to add channel dimension\n",
    "x_train_cnn = x_train.reshape((60000, 28, 28, 1))\n",
    "x_test_cnn = x_test.reshape((10000, 28, 28, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80851a0a-982c-444b-a8ea-50ecfe4ac04b",
   "metadata": {},
   "source": [
    "## Step B2: Build the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c152e7b1-1881-4941-aa50-ee0670b5bf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Input(shape=(28, 28, 1)),                  \n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e62e891-4a07-4669-aac9-69e6230ac044",
   "metadata": {},
   "source": [
    "## Step B3: Compile and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc7b49d8-d11d-48f8-beeb-d5a9cce8d48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.8361 - loss: 0.5891 - val_accuracy: 0.9747 - val_loss: 0.0908\n",
      "Epoch 2/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9761 - loss: 0.0806 - val_accuracy: 0.9810 - val_loss: 0.0650\n",
      "Epoch 3/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9832 - loss: 0.0520 - val_accuracy: 0.9836 - val_loss: 0.0569\n",
      "Epoch 4/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9871 - loss: 0.0402 - val_accuracy: 0.9828 - val_loss: 0.0523\n",
      "Epoch 5/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9894 - loss: 0.0325 - val_accuracy: 0.9866 - val_loss: 0.0461\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2a2e39f6d10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "cnn_model.fit(x_train_cnn, y_train_cat, epochs=5, batch_size=128, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d8f6ea-6b36-4b7f-bb45-752f7090e290",
   "metadata": {},
   "source": [
    "## Step B4: Evaluate CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "812fb858-0717-4b0a-8f0e-5242f18b0f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9846 - loss: 0.0455\n",
      "CNN Test Accuracy: 98.81 %\n"
     ]
    }
   ],
   "source": [
    "test_loss_cnn, test_acc_cnn = cnn_model.evaluate(x_test_cnn, y_test_cat)\n",
    "print(f\"CNN Test Accuracy: {test_acc_cnn * 100:.2f} %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc6daa8-23e5-4256-ab5a-d558c7a7ea1a",
   "metadata": {},
   "source": [
    "# Predict and Visualize a Digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26da50f1-411c-4f6f-b7d0-4ce14413bb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGZCAYAAABmNy2oAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAASi0lEQVR4nO3ce4xVZ9nw4XvoDIwcCgYQCg2DATkYwQZKOaSNVCyttZT0IEFsCkixEg8ItU21aME2agIKxkOM4ZwQilpsDKagtqBGQGojidQGLBYIQolAQLTYYWC9f3wfd8rLobN2GYbyXlcyf7Bm3Xs9MLB/s/ZsnqqiKIoAgIho0dwLAODyIQoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJApcFEuXLo2qqqr8qK6ujmuvvTYmT54c//jHPy7JGnr27BmTJk3KX2/YsCGqqqpiw4YNpR5n48aNMXv27Dhy5MhFXV9ExKRJk6Jnz54Vz//rX/+Kxx57LPr06ROtW7eO7t27x8c//vF46aWXLt4i+T9NFLiolixZEps2bYpf//rXMXXq1Fi5cmXcdNNN8Z///OeSr2XQoEGxadOmGDRoUKm5jRs3xpw5c5okCm/XmDFjYsGCBTF16tT45S9/Gd/61rdi69atMXz48Ni9e3dzL48rQHVzL4Arywc+8IG4/vrrIyLi5ptvjpMnT8YTTzwRzzzzTHzyk58858zrr78erVu3vuhrufrqq2PYsGEX/XGbyyuvvBK/+93vYtasWfHwww/n8d69e8eIESNi9erVMWPGjGZcIVcCdwo0qdNPyqe/i500aVK0bds2/vKXv8To0aOjXbt2MWrUqIiIqK+vjyeffDL69esXrVq1is6dO8fkyZPjn//85xmPeeLEiXjkkUeia9eu0bp167jxxhtjy5YtZ137fC8f/fGPf4wxY8ZEx44do7a2Nnr16hVf/OIXIyJi9uzZ+YT73ve+N18Oe/NjrFq1KoYPHx5t2rSJtm3bxq233hp//vOfz7r+0qVLo2/fvtGqVavo379/LF++vKI/w9NqamoiIqJ9+/ZnHO/QoUNERNTW1r6tx4cIdwo0sVdeeSUiIjp37pzH6uvr484774wHH3wwHn300WhoaIhTp07F2LFj4/e//3088sgjMWLEiNi9e3c8/vjjMXLkyPjTn/4U73rXuyIiYurUqbF8+fL40pe+FLfcckts27Yt7r777jh27NhbrmfdunUxZsyY6N+/f3znO9+JHj16xK5du+JXv/pVREQ88MADcfjw4fje974Xq1evjmuuuSYiIt7//vdHRMQ3vvGNmDVrVkyePDlmzZoV9fX1MXfu3Ljppptiy5Yted7SpUtj8uTJMXbs2Pj2t78dR48ejdmzZ8cbb7wRLVqc+b3YpEmTYtmyZfHqq69e8OcNdXV1MXbs2Jg/f34MHjw4hgwZEnv37o0vfOEL0aNHjxg/fnwjvypwAQVcBEuWLCkioti8eXNx4sSJ4tixY8WaNWuKzp07F+3atStee+21oiiKYuLEiUVEFIsXLz5jfuXKlUVEFE8//fQZx1944YUiIoof/vCHRVEUxcsvv1xERDFjxowzzluxYkUREcXEiRPz2Pr164uIKNavX5/HevXqVfTq1as4fvz4eX8vc+fOLSKiePXVV884vmfPnqK6urr4/Oc/f8bxY8eOFV27di3GjRtXFEVRnDx5sujWrVsxaNCg4tSpU3nerl27ipqamqKuru6M+U996lPFVVddVezateu8azqtvr6+mDp1ahER+TFw4MCz1gqV8vIRF9WwYcOipqYm2rVrF3fccUd07do1nn322ejSpcsZ591zzz1n/HrNmjXRoUOHGDNmTDQ0NOTHddddF127ds2Xb9avXx8RcdbPJ8aNGxfV1Re+8d2xY0fs3LkzpkyZUtFLLevWrYuGhoa4//77z1hjbW1tfOhDH8o1bt++Pfbt2xcTJkyIqqqqnK+rq4sRI0ac9biLFi2KhoaGqKure8s1TJs2LZ5++umYP39+/Pa3v41Vq1ZFy5Yt48Mf/rAfNHNRePmIi2r58uXRv3//qK6uji5duuTLL2/WunXruPrqq884duDAgThy5Ei0bNnynI978ODBiIg4dOhQRER07dr1jM9XV1dHx44dL7i20z+buPbaaxv3m/lfDhw4EBERQ4YMOefnT78sdL41nj62a9euiq6/du3aWLRoUfz0pz+Ne++9N4+PHj06evbsGbNnz44lS5ZU9NhwmihwUfXv3z/ffXQ+b/7u+bROnTpFx44dY+3ateecadeuXUREPvG/9tpr0b179/x8Q0NDPhmfz+mfa+zdu/eC551Pp06dIiLiZz/72QW/q3/zGv+3cx1rrK1bt0bE2VHq0KFD9O7dO7Zt21bxY8NposBl4Y477oinnnoqTp48GUOHDj3veSNHjoyIiBUrVsTgwYPz+E9+8pNoaGi44DX69OkTvXr1isWLF8fMmTOjVatW5zzv9PHjx4+fcfzWW2+N6urq2Llz51kvf71Z375945prromVK1fGzJkzM4K7d++OjRs3Rrdu3S64zvM5Pbd58+YzonTo0KHYsWNHvosL3g5R4LIwfvz4WLFiRdx+++0xffr0uOGGG6Kmpib27t0b69evj7Fjx8Zdd90V/fv3j/vuuy8WLFgQNTU18ZGPfCS2bdsW8+bNO+slqXP5wQ9+EGPGjIlhw4bFjBkzokePHrFnz55Yt25drFixIiIiBgwYEBER3/3ud2PixIlRU1MTffv2jZ49e8bXv/71eOyxx+Lvf/973HbbbfHud787Dhw4EFu2bIk2bdrEnDlzokWLFvHEE0/EAw88EHfddVdMnTo1jhw5ErNnzz7nS0pTpkyJZcuWxc6dOy94B3L33XfH1772tZg2bVrs3bs3Bg0aFPv374+5c+fG66+/HtOnT6/wTx/epLl/0s2V4fS7j1544YULnjdx4sSiTZs25/zciRMninnz5hUf/OAHi9ra2qJt27ZFv379igcffLD429/+lue98cYbxUMPPVS85z3vKWpra4thw4YVmzZtKurq6t7y3UdFURSbNm0qPvrRjxbt27cvWrVqVfTq1eusdzN9+ctfLrp161a0aNHirMd45plniptvvrm4+uqri1atWhV1dXXFvffeW/zmN7854zEWLlxYvO997ytatmxZ9OnTp1i8eHExceLEs959dPodWY15B9H+/fuLz33uc0Xv3r2L2traolu3bsXHPvaxYtOmTW85C41RVRRF0bxZAuBy4S2pACRRACCJAgBJFABIogBAEgUAUqP/89q5tiYA4J2jMf8DwZ0CAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAKm6uRdA82vRovz3Bl/96ldLzzz++OOlZypVVVV1Sa6zYMGC0jPz58+v6Fp79uypaA7KcKcAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYBUVRRF0agTL9EGY7w9w4YNKz3z6KOPlp4ZM2ZM6Rn+n7/+9a8Vzd14442lZ44ePVrRtbgyNebp3p0CAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSDfEugauuuqr0zLhx4yq61sKFC0vP1NbWlp5p5F+bM7z88sulZyIi1q5dW3qma9eupWc+8YlPlJ65lP8ubrjhhtIzL774YhOshHcqG+IBUIooAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAg2SX1EpgxY0bpmXnz5jXBSi6e5557rvTM6NGjm2AlF8/mzZtLzwwZMqQJVnJu27dvLz0zatSo0jP79+8vPcM7g11SAShFFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAUnVzL4Dm9+STT5ae+dGPftQEK2len/3sZ0vPLFy4sPTMwIEDS89ERPTt27f0zLPPPlt65vbbby89s2/fvtIzXJ7cKQCQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAINkQjxgwYEDpmYMHDzbBSprXiy++WHrmtttuKz3z/PPPl56JiOjXr1/pmUq+tkOHDi098/Of/7z0DJcndwoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEg2xLsEKt0A7VIZO3Zs6ZmvfOUrpWeWLVtWeiYiYteuXRXNXQrHjx8vPVNbW9sEKzm3EydOlJ45cuTIxV8I7xjuFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgFRVFEXRqBOrqpp6LVesFi3Kt3fChAkVXavSnUgvhYMHD1Y0N3PmzNIzK1asqOhaZU2bNq30zPe///0mWMm5bdiwofTMqFGjLv5CuCw05unenQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIN8S5T1dXVFc1df/31pWd+8YtflJ7p2LFj6ZlK/fe//y09U8mmbtu3by8989JLL5We6dKlS+mZiIj6+vrSM927dy89c/jw4dIzvDPYEA+AUkQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACDZEI+47rrrSs+sXr269Eylm+i1bdu2orkrzYQJE0rPrFq1qglWwjuVDfEAKEUUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQBSdXMvgOa3devW0jPDhw8vPTN06NDSMxERc+bMKT0zcODAiq51Kezbt6+iuYMHD17klcDZ3CkAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACBVFUVRNOrEqqqmXgucU5cuXUrPVLrp3OXsxIkTpWe6d+9eeubQoUOlZ3hnaMzTvTsFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgVTf3AuCt1NfXN/cSzquS3Vi7detW0bVqampKzzz33HOlZz796U+XntmyZUvpGS5P7hQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBsiMdlb/z48c29hPO65ZZbSs9UsuFcRMT06dNLzwwYMKD0zMyZM0vPXM5fI8pxpwBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgGRDPC57nTp1uiTXeeqpp0rPbN++vfTMww8/XHomIuLkyZOlZ2bMmFF65p577ik9M2XKlNIzixYtKj1D03OnAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAZEM8+P8aGhpKzxRFUXqmko3tIirbSO8zn/lM6ZnWrVuXnhk8eHDpGRviXZ7cKQCQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIFUVjdzRq6qqqqnXAufUq1ev0jM7duwoPXP06NHSM3V1daVnjh07VnqmUpVcq5IN8f7whz+Unhk5cmTpmYiIU6dOVTRH4zZwdKcAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgCk6uZeALyVw4cPX5LrtG/fvvTM888/X3pm4MCBpWcqVV19af6Jb9y4sfSM3U4vT+4UAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQqoqiKBp1YlVVU68Fzqmmpqb0zI9//OPSM/fff3/pmSvRmjVrSs/cd999pWeOHTtWeoa3pzFP9+4UAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQbIjHFam2trb0zEMPPVR65s477yw9061bt9IzERGrV68uPfPvf/+79Mw3v/nNS3IdLj0b4gFQiigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACQb4gH8H2FDPABKEQUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgCpurEnFkXRlOsA4DLgTgGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGA9D8PmKW/Kk6aNQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Predict one image\n",
    "image_index = 1267\n",
    "img = x_test_cnn[image_index].reshape(1, 28, 28, 1)\n",
    "prediction = cnn_model.predict(img)\n",
    "predicted_label = np.argmax(prediction)\n",
    "\n",
    "# Show image\n",
    "plt.imshow(x_test[image_index], cmap='gray')\n",
    "plt.title(f\"Predicted: {predicted_label}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3852acbd-0820-4760-a09a-3db035d7b958",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
